train
library(ISLR)
set.seed(13435)
train <- sample(777, 389)
train
library(ISLR)
set.seed(13435)
train <- sample(777, 389)
train
college <- read.csv("/Users/shijiabian/Documents/College.csv", header = TRUE,
sep = ",")
college <- read.csv("College.csv", header = TRUE,
sep = ",")
rownames(college)=college[,1]
college=college[,-1]
dim(college)
college <- college[, -c(3, 4)]
college
head(college)
names(college)
attach(college)
dim(college)
trainCollege=college[train,]
testCollege=college[-train,]
attach(trainCollege)
attach(testCollege)
?lm.fit
lm.fit<-lm(App~.,data=trainCollege)
lm.fit<-lm(Apps~.,data=trainCollege)
mse.Train <- mean((trainCollege$Apps-predict(lm.fit,trainCollege))^2)
mse.Train <- mean((testCollege$Apps-predict(lm.fit,testCollege))^2)
mse.Train <- mean((trainCollege$Apps-predict(lm.fit,trainCollege))^2)
mse.Test <- mean((testCollege$Apps-predict(lm.fit,testCollege))^2)
summary(lm.fit)
?fix()
rm(list=ls())
library(MASS)
Boston
?Boston
dim(Boston)
pairs(Boston)
pheatmap(t(scale(as.matrix(Boston))),
show_colnames=FALSE)
source("http://bioconductor.org/biocLite.R") #adds bioconductor site as a package source
BiocLite(“pheatmap”) #downloads and install pheatmap package from bioconductor
library(pheatmap) #loads pheatmap package
install.packages(“RColorBrewer”) #donwnloads and installs a package with useful color themes
Library(RColorBrewer) #load RcolorBrewer package
BiocLite(“pheatmap”)
install.packages(“RColorBrewer”)
par(mfrow = c(2, 2))
plot(Boston$nox, Boston$crim)
plot(Boston$rm, Boston$crim)
plot(Boston$age, Boston$crim)
plot(Boston$dis, Boston$crim)
hist(Boston$crim, breaks = 50)
hist(Boston$crim, breaks = 50)
hist(Boston$crim, breaks = 50)
plot(Boston$nox, Boston$crim)
plot(Boston$rm, Boston$crim)
plot(Boston$age, Boston$crim)
plot(Boston$dis, Boston$crim)
par(mfrow = c(2, 2))
plot(Boston$nox, Boston$crim)
plot(Boston$rm, Boston$crim)
plot(Boston$age, Boston$crim)
plot(Boston$dis, Boston$crim)
par(mfrow = c(2, 2))
plot(Boston$nox, Boston$crim)
plot(Boston$rm, Boston$crim)
plot(Boston$age, Boston$crim)
plot(Boston$dis, Boston$crim)
hist(Boston$crim, breaks = 50)
pairs(Boston[Boston$crim < 20, ])
install.packages("RColorBrewer")
pheatmap(cor(Boston, use="pairwise.complete.obs"))
install.packages(c("Hmisc", "gplots", "RColorBrewer", "ggplots2",
"scales", "plyr", "pheatmap", "car", "xtable", "reshape",
"gridExtra","GGally"), dependencies = TRUE)
source("http://bioconductor.org/biocLite.R")
biocLite(c("limma", "ggbio","GenomicRanges"))
pheatmap(cor(Boston, use="pairwise.complete.obs"))
summary(Boston$rad)
source("http://bioconductor.org/biocLite.R")
biocLite(c("RColorBrewer", "pheatmap"))
library("pheatmap")
library("RColorBrewer")
library("pheatmap")
library("RColorBrewer")
library("RColorBrewwe"
)
library("RColorBrewer")
library("pheatmap")
install.packages("plyr")
library("pheatmap")
pheatmap(t(scale(as.matrix(Boston))),
show_colnames=FALSE)
pheatmap(cor(Boston, use="pairwise.complete.obs"))
par(mfrow=c(2,2))
hist(Boston$crim, main="Crime Rates\n (note the long tail)",breaks="FD")
hist(Boston$crim, main="Crime Rates with y-axis limited",
ylim=c(0, 40), breaks="FD")
hist(Boston$tax, main="Tax rates\n (note some high-tax outliers)", breaks="FD")
hist(Boston$ptratio, main="Pupil-teacher ratio\n (no real outliers)", breaks="FD")
pheatmap(t(scale(as.matrix(Boston))),
show_colnames=TRUE)
pheatmap(t(scale(as.matrix(Boston))),
show_colnames=FALSE)
fix(Boston)
lm.fit=lm(medv~lstat,data=Boston)
attach(Boston)
lm.fit=lm(medv~lstat)
summary(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval="confidence")
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval="prediction")
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit,lwd=3,col="red")
plot(lstat,medv,col="red")
plot(lstat,medv,pch=20)
plot(lstat,medv,pch="+")
plot (1:20 ,1:20, pch =1:20)
par(mfrow =c(2,2))
plot(lm.fit)
output. You should be getting:
[1] 5.1 4.1 4.1 2.1
par("mar")
par(mar=c(1,1,1,1))
par(mfrow =c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(predict (lm.fit), rstudent (lm.fit))
install.packages(lubridate)
install.packages("lubridate")
install.packages("sclae")
install.packages("scale")
y
install.packages("Scale")
install.packages("Scales")
install.packages("scales")
train<-read.csv("train_bike.csv")
train<-read.csv("train_bike.csv")
test<-read.csv("test_bike.csv")
test$registered=0
test$casual=0
test$count=0
data=rbind(train,test)
str(data)
table(is.na(data))
par(mfrow=c(4,2))
par(mar=rep(2,4))
hist(data$season)
par(mar=rep(1,2))
par(mar=c(1,2,1,2))
hist(data$season)
hist(data$weather)
hist(data$humidity)
hist(data$holiday)
hist(data$workingday)
hist(data$temp)
hist(data$atemp)
hist(data$windspeed)
?prop.table
prop.table(table(data$weather))
data$season=as.factor(data$season)
data$weather=as.factor(data$weather)
data$holiday=as.factor(data$holiday)
data$workingday=as.factor(data$workingday)
date$hour=substr(date$datetime,12,13)
date$hour=substr(date$datetime,12,13)
names(data)
data$hour=substr(data$datetime,12,13)
data$hour=as.factor(data$hour)
train=data[as.integer(substr(data$datetime,9,10))<20,]
test=data[as.integer(substr(data$datetime,9,10))>19,]
boxplot(train$count~train$hour,xlab="Hour",ylab="Count of Users")
boxplot(train$casual~train$hour,xlab="Hour",ylab="Count of Users")
boxplot(train$registered~train$hour,xlab="Hour",ylab="Count of Users")
boxplot(log(train$count)~train$hour,xlab="Hour",ylab="Count of Users")
date=substr(data$datetime,1,10)
days<-weekdays(as.Date(date))
data$day=days
boxplot(train$casual~data$days,xlab="Hour",ylab="Count of Users")
boxplot(data$casual~data$days,xlab="Hour",ylab="Count of Users")
boxplot(data$casual~data$day,xlab="Hour",ylab="Count of Users")
sub=data.frame(train$registered,train$casual, train$count,train$temp,train$humidity,train$atemp,train$windspeed)
cor(sub)
boxplot(log(train$count)~train$hour,xlab="hour",ylab="log(count)")
train$hour=as.integer(train$hour)
test$hour=as.integer(test$hour)
library(rpart)
library(rattle)
install.packages("rattle")
library(rattle)
install.packages("rpart.plot")
library(rpart.plot)
library(RColorBrewer)
d=rpart(registered~hour,data=train)
fancyRpartPlot(d)
data=rbind(train,test)
data$dp_reg[data$hour<8]=1
data$dp_reg[data$hour>=22]=2
data$dp_reg[data$hour>9 & data$hour<18]=3
data$dp_reg[data$hour==8]=4
data$dp_reg[data$hour==9]=5
data$dp_reg[data$hour==20|data$hour==21]=6
data$dp_reg[data$hour==19|data$hour==18]=7
data$year_part[data$year=='2011']=1
data$year_part[data$year=='2011' & data$month>3]=2
data$year_part[data$year=='2011' & data$month>6]=3
data$year_part[data$year=='2011' & data$month>9]=4
data$year_part[data$year=='2012']=5
data$year_part[data$year=='2012' & data$month>3]=6
data$year_part[data$year=='2012' & data$month>6]=7
data$year_part[data$year=='2012' & data$month>9]=8
table(data$year_part)
data$year_part[data$year=='2011']=1
?predict
rm=list(ls())
library(ggplot2)
library(scales)
train<-read.csv("train_titanic.csv",header = T,as.is=TRUE)
test<-read.csv("test_titanic.csv",header = T,as.is=TRUE)
fam_name <- function(x){}
fam_name <- function(x){fmn<-strsplit(x,',') fmn[[1]][1]}
fam_name <- function( x ) {
fmn <- strsplit( x, ',' )
fmn[[1]][1]
}
fam_name <- function( x ) {
fmn <- strsplit( x, ',' )
fmn[[1]][1]
}
train$Family<-sapply(train$Name,fam_name,USE.NAMES = FALSE)
test$Family<-sapply(test$Name,fam_name,USE.NAMES = FALSE)
train <- data.frame(survived=train$Survived,
pclass=train$Pclass,
gender=train$Sex,
Family=train$Family,
test=FALSE )
test <- data.frame(survived=test$Survived,
pclass=test$Pclass,
gender=test$Sex,
Family=test$Family,
test=TRUE )
test  <- data.frame(survived=NA,
pclass=test$Pclass,
gender=test$Sex,
Family=test$Family,
test=TRUE )
combined <- rbind(train,test)
family_count <- table(factor(combined$Family))
get_coun <- function(fam){family_count[[fam]]}
combined$fam_count <- sapply(combined$Family,FUN=get_count)
get_count <- function(fam) { family_count[[fam]] }
combined$fam_count <- sapply(combined$Family,FUN=get_count)
conmbined$alone <- factor(ifelse(combined$fam_count>1,"with family","alone"))
combined$alone <- factor(ifelse(combined$fam_count>1,"with family","alone"))
temp <- combined[ !combined$test, ]
p4 <- ggplot( temp, aes(x=alone, y=survived) )  +
stat_summary(fun.y = mean, ymin=0, ymax=1, geom="bar", size=1, fill=muted("blue")) +
xlab('traveling') + ylab('survival rate') +
ggtitle("Suvival rate as function of traveling with or without family")
print(p4)
png("survival_by_travel_with_or_without_family.png", width=400, height=400)
print(p4)
dev.off()
p3 <- ggplot(temp, aes(x=alone, y=survived))  +
stat_summary(fun.y = mean, ymin=0, ymax=1, geom="bar", size=1, fill=muted("blue")) +
facet_grid(pclass~gender) +
xlab( 'traveling') + ylab( 'survival rate' ) +
ggtitle("Suvival rate as function of Class and Gender")
png("survival_by_class_and_gender.png", width=800, height=600)
print(p3)
dev.off()
library(ISLR)
library(tree)
install.packages("tree")
library(tree)
attach(Carseats)
High)ifelse(Sales<=8,"No","Yes")
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats,High)
tree.carseats <- tree(High~.-Sales,Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed(2)
train=sample(1:nrow(Carseats),200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
tree.carseats =tree(High∼.-Sales ,Carseats ,subset =train )
tree.pred=predict(tree.carseats,Carseats.test,type = "class")
table(tree.pred,High.test)
(86+57)/200
set.seed(3)
cv.carseats=cv.tree(tree.carseats,FUN = prune.misclass)
par(mfrow=c(1,2))
plot(cv.carseats$size ,cv.carseats$dev ,type="b")
plot(cv.carseats$k ,cv.carseats$dev ,type="b")
prune.carseats =prune.misclass (tree.carseats ,best =9)
plot(prune.carseats )
text(prune.carseats ,pretty =0)
tree.pred=predict (prune.carseats , Carseats .test ,type=" class ")
tree.pred=predict (prune.carseats , Carseats.test ,type=" class ")
tree.pred=predict(prune.carseats,Carseats.test ,type=" class ")
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred ,High.test)
rep(1:4,2)
rm=list(ls())
rmlist(ls())
?par
par(mar=c(3,2,0,0))
par(mfrow=c(4,4), mar=c(2, 2, 1, 0))
library(ISLR)
data(College)
for(i in 2:17)
boxplot(college[,i]~college[,1],xlab"",main=colnames(College)[i])
boxplot(College[,i]~College[,1],xlab"",main=colnames(College)[i])
boxplot(College[, i] ~ College[, 1], xlab="", main=colnames(College)[i])
for (i in 2:17)
boxplot(College[, i] ~ College[, 1], xlab="", main=colnames(College)[i])
College$Elite <- College$Top10perc > 50
fix(College)
test = matrix(rnorm(200), 20, 10)
View(test)
View(test)
test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3
test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2
test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4
View(test)
View(test)
colnames(test) = paste("Test", 1:10, sep = "")
rownames(test) = paste("Gene", 1:20, sep = "")
pheatmap(test)
library(pheatmap)
pheatmap(test)
pheatmap(test, kmeans_k = 2)
pheatmap(test, scale = "row", clustering_distance_rows = "correlation")
library(plyr)
library(XML)
urls <- paste("http://crantastic.org/popcon?page=", 1:10, sep = "")
# scrape all the data from the URLs into one big data.frame
packages.df <- ldply(urls, function(url)readHTMLTable(url)[[1]])
# turn the "Users" column from factor to numeric
packages.df$Users <- as.numeric(as.character(packages.df$Users))
# sort by decreasing "Users"
packages.df <- arrange(packages.df, desc(Users))
# print the 50 most used packages
head(packages.df$`Package Name`, 50)
#load packages
# load packages
library(dplyr)
library(hflights)
library(plyr)
library(plyr);library(dplyr)
install.packages("hflights")
library(hflights)
# explore data
setwd("~/Statistical Learning R/Coursera/Project")
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(tidyr)
library(gplots)
library(ggplot2) # Visualise data.
library(plyr)
library(dplyr) # Data preparation and pipes %>%.
library(FSelector) # Feature selection.
library(pheatmap) # Heatmaps.
trainpath <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainpath <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testpath <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainpath, destfile=trainFile, method="libcurl")
}
if (!file.exists(testFile)) {
download.file(testpath, destfile=testFile, method="libcurl")
}
training <- read.csv(trainFile, na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(testFile, na.strings=c("NA","#DIV/0!",""))
RMTrain <- training[, colSums(is.na(training)) <= 0.6*nrow(training)]
RMTest <- testing[, colSums(is.na(testing)) <= 0.6*nrow(testing)]
RMTrain <- RMTrain[-c(1:7)]
RMTest <- RMTest[-c(1:7)]
RMTrain <- RMTrain[-c(1:7)]
RMTest <- RMTest[-c(1:7)]
RMTrain <- training[, colSums(is.na(training)) <= 0.6*nrow(training)]
RMTest <- testing[, colSums(is.na(testing)) <= 0.6*nrow(testing)]
RMTrain <- training[, colSums(is.na(training)) <= 0.6*nrow(training)]
RMTest <- testing[, colSums(is.na(testing)) <= 0.6*nrow(testing)]
View(RMTest)
View(RMTrain)
RMTrain <- RMTrain[-c(1:7)]
RMTest <- RMTest[-c(1:7)]
zerovar <- nearZeroVar(RMTrain, saveMetrics = T)
RMTrain <- RMTrain[, !zerovar$nzv]
set.seed(21541)
inTrain <- createDataPartition(RMTrain$classe, p=0.60, list=F)
mytraining <- RMTrain[inTrain,]
mytesting <- RMTrain[-inTrain,]
dim(mytraining);dim(mytesting)
install.packages("corrplot")
library(corrplot)
pheatmap(t(scale(as.matrix(mytraining[,-53]))),show_colnames=FALSE)
Mytrain_scale<- scale(mytraining[,-53],center=TRUE,scale=TRUE);
corrplot(corMatMy, order = "hclust")
corrplot(descrCor, order = "hclust")
descrCor <-  cor(Mytrain_scale)
corrplot(descrCor, order = "hclust")
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .8)
summary(descrCor[upper.tri(descrCor)])
pheatmap(t(descrCor))
pheatmap(t(descrCor),show_colnames=FALSE)
my_palette <- colorRampPalette(c("red", "yellow", "green"))(n = 299)
col_breaks = c(seq(-1,0,length=100),
seq(0,0.7,length=100),
seq(0.7,1,length=100))
heatmap.2(descrCor, key = T, cexRow = 0.8, dendrogram="column", cexCol = 0.8, margins=c(9,12), density.info="none", trace="none", ColV="NA")
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .8)
summary(descrCor[upper.tri(descrCor)])
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .8)
summary(descrCor[upper.tri(descrCor)])
library(reshape2)
set.seed(21541)
modTree <- train(mytraining$classe ~ ., data = mytraining, method="rpart")
print(modTree, digits=3)
set.seed(21541)
modTree <- train(mytraining$classe ~ ., data = mytraining, method="rpart",trControl=trainControl(method = "cv", number = 10))
print(modTree, digits=3)
modTree <- train(mytraining$classe ~ ., data = mytraining, method="rpart",preProcess=c("center", "scale"),trControl=trainControl(method = "cv", number = 10))
print(modTree, digits=3)
print(modTree$finalModel)
predictionsTree <- predict(modTree, mytesting, type = "class")
print(confusionMatrix(predictions, mytesting$classe))
predictionsTree <- predict(modTree, newdata =  mytesting)
print(confusionMatrix(predictions, mytesting$classe))
print(confusionMatrix(predictionsTree, mytesting$classe))
modTree_No_prepr <- train(mytraining$classe ~ ., data = mytraining, method="rpart",trControl=trainControl(method = "cv", number = 10))
predictionsTree <- predict(modTree_No_prepr, newdata =  mytesting)
print(confusionMatrix(predictionsTree, mytesting$classe))
set.seed(21541)
boostFit <- train(classe ~ ., method = "gbm", data = mytraining, verbose = F, trControl = trainControl(method = "cv", number = 10))
library(gbm)
set.seed(21541)
boostFit <- train(classe ~ ., method = "gbm", data = mytraining, verbose = F, trControl = trainControl(method = "cv", number = 10))
boostFit
plot(boostFit, ylim = c(0.9, 1))
plot(boostFit, ylim = c(0.9, 1))
par(mfrow =c(1,2))
plot(boostFit ,i="rm")
plot(boostFit ,i=" lstat ")
set.seed(21541)
rfFit <- train(classe ~ ., method = "rf", data = mytraining, importance = T, trControl = trainControl(method = "cv", number = 10))
rfFit
training <- read.csv(trainFile, na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(testFile, na.strings=c("NA","#DIV/0!",""))
RMTrain <- training[, colSums(is.na(training)) <= 0.6*nrow(training)]
RMTest <- testing[, colSums(is.na(testing)) <= 0.6*nrow(testing)]
plot(rfFit, ylim = c(0.9, 1))
plot(rfFit, ylim = c(0.9, 1))
dev.off()
dev.off()
plot(rfFit, ylim = c(0.9, 1))
rf.prediction <- predict(rfFit, RMTest)
cfMatrix <- confusionMatrix(rf.prediction, RMTest$classe)
cfMatrix$table
rf.prediction <- predict(rfFit, mytesting)
cfMatrix <- confusionMatrix(rf.prediction, mytesting$classe)
cfMatrix$table
oose <- 1 - as.numeric(confusionMatrix(rf.predictions, mytesting$classe)$overall[1])
oose
oose <- 1 - as.numeric(confusionMatrix(rf.prediction, mytesting$classe)$overall[1])
oose
rf.prediction <- predict(rfFit, mytesting,type="class")
cfMatrix <- confusionMatrix(rf.prediction, mytesting$classe)
cfMatrix$table
rf.prediction <- predict(rfFit, mytesting)
cfMatrix <- confusionMatrix(rf.prediction, mytesting$classe)
cfMatrix$table
plot(rfFit$finalModel)
rfFit$finalModel
Prediction <- predict(rfFit, RMTest)
Prediction
varImpPlot(rfFit$finalModel,cex=1.5, col ="black", type=2)
varImpPlot(rfFit$finalModel,cex=1.5, col ="black", type=1)
varImpPlot(rfFit$finalModel,cex=1.5, col ="black", type=3)
varImpPlot(rfFit$finalModel,cex=1.0, col ="blue", type=2)
varImpPlot(rfFit$finalModel,cex=0.9, col ="blue", type=2)
install.packages("rmarkdown")
install.packages("rmarkdown")
render("PML_PROJECT.Rmd")
library(rmarkdown)
render("PML_PROJECT.Rmd")
render("PML_PROJECT.Rmd",html_document(toc = TRUE))
library(caret)
set.seed(21541)
inTrain <- createDataPartition(RMTrain$classe, p=0.60, list=F)
mytraining <- RMTrain[inTrain,]
mytesting <- RMTrain[-inTrain,]
dim(mytraining);dim(mytesting)
